---
title: "36-402 DA Exam 1 Code Submission"
author: "Carl Yang (yufeiy3)"
date: "4/3/2020"
output:
  pdf_document: default
  word_document: default
  html_document:
    df_print: paged
linestretch: 1.241
fontsize: 12pt
fontfamily: newtxtext,newtxmath
---


```{r setup, include = FALSE}
## By default, do not include R source code in the PDF. We do not want to see
## code, only your text and figures.
knitr::opts_chunk$set(echo = FALSE)
college = read.csv("college-data.csv")
```


# Exploratory Data Analysis


```{r}
#pairs(college[, c(4:8)], pch=".", labels = c("PRICE", "SAT_AVG_ALL", "PCTPELL", "PCTFLOAN", "MD_EARN_WNE_P10"))

#pairs(log(college[, c(4:8)]), pch=".", labels = c("PRICE", "SAT_AVG_ALL", "PCTPELL", "PCTFLOAN", "MD_EARN_WNE_P10"))

# par(mfrow=c(2,2))
# hist(college$PRICE, xlab="Average Net Price", main = "Average Net Price")
# hist(college$SAT_AVG_ALL, xlab="Mean SAT Score", main="Mean SAT Score")
# hist(college$PCTPELL, xlab="Pell Grant", main="Pell Grant")
# hist(college$PCTFLOAN, xlab="Student Loan", main="Student Loan")

```

The "college" dataset from College Scoreboard contains information about 1300 American colleges and universities, their tuition costs and total enrollment of undergraduate students, and prior education and economic status of students. In order to find the relationship between the worthiness of attending schools with high tuition, the variable "Median Earnings" (MD_MARN_WNE_P10), which records the median earnings (dollars) of students working and not enrolled 10 years after entry, would be a good indicator of the payback of education expense. Here we use several other related variables to learn the relationship: "Price" (PRICE), which is the average net price students pay for their college education, including tuition and other fees minus financial aid; "SAT Score" (SAT_AVG_ALL), which is the mean equivalent SAT score for admitted students; "Pell Grant" (PCTPELL), for fraction of all undergraduates who received a federal Pell grant for tuition; and "Student Loan" (PCTFLOAN), which indicates fraction of all undergraduates receiving a federal student loan. **(1)** The histograms show that all these selected variables are approximately normally distributed, with a few skewness that can be ingonred, except for the Median Earnings that we are mainly interested. 

As specified above, Median Earnings should be our response variable. However, histogram shows that the distribution of Median Earnings is unimodal and severely right skewed with outliers at the tail. **(2)** Thus we propose that a log-transformation on the response variable to make the distribution more normal, as Figure 1 suggests.

```{r, fig.width=5, fig.height=4, fig.cap="Histogram displaying the distributions of Median Earnings"}
#boxplot(MD_EARN_WNE_P10~CONTROL, data = college, main = "Median Earnings by Instuition Types")
par(mfrow = c(1,2))
hist(college$MD_EARN_WNE_P10, xlab="Median Earnings", main="Median Earnings")
hist(log(college$MD_EARN_WNE_P10), xlab="Median Earnings", main="Log-transformed Median Earnings")
```

Figure 2 depicts the multivariate relationship between the explanatory variables we choose and the response variables. We can see that SAT scores is strongly correlated with Median Earnings with a positive relationship, and Price has a somewhat weaker positive correlation. Meanwhile, the value of fraction of students who received Pell grant has a strong negative correlation with Median Earnings and the variable Student Loan has a weaker negative one. Lowess curves and individual residual analysis show that only Student Loan has an approximately linear relationship with the response variable, and the other three seem have be non-linear relationships. **(3)**
   
```{r, message=FALSE,fig.width=5, fig.height=4, fig.cap="Multivariate EDA showing the relationship between predictors and the response "}
library(GGally)
ggpairs(college, columns = c(4:8), lower = list(continuous = wrap("smooth", method = "loess", pch=".")))
```
   

```{r, eval=FALSE}
# plot(college$SAT_AVG_ALL, college$MD_EARN_WNE_P10, pch=".")
# lines(lowess(college$MD_EARN_WNE_P10 ~ college$SAT_AVG_ALL, f=8/10, iter=3), lty=1, col="blue")
```

   
It is interesting to find that both Price and SAT scores are positively correlated with Median Earnings. This might suggest that students who pay for high tuitions and have good prior education performance are likely to earn more after they graduate. On the other hand, SAT scores are negatively correlated with financial aid variables, suggesting that students with weaker academic achievements tend to rely on financial aid to complete college education. And these students are more likely to earn less in the future compared to those who do not need financial aid.**(4)** These initial guesses might help us understand students' money-making abilities in further investigation. 


# Modeling & Diagnostics

   
```{r, message=FALSE, results='hide'}
library(mgcv)
model1 = lm(log(MD_EARN_WNE_P10) ~ PRICE + SAT_AVG_ALL + PCTPELL + PCTFLOAN , data = college)
model2 = gam(log(MD_EARN_WNE_P10) ~ s(PRICE, k = 4 + 1, fx = TRUE) + s(SAT_AVG_ALL, k = 4 + 1, fx = TRUE) + s(PCTPELL, k = 4 + 1,          fx = TRUE) + PCTFLOAN , data = college)
summary(model1)
summary(model2)
```

The EDA told us that response variable Median Earnings have a strong correlation with the four predictors we choose after a log transformation. **(1) ** Thus we make the following linear model as required:

Linear Model 1: $log(Median Earnings) \sim \beta_0 + \beta_1(PRICE) + \beta_2(SAT) + \beta_3(PCTPELL) + \beta_4(PCTFLOAN) + \epsilon$ 

The multivariate EDA above also shows that the explanatory variables PRICE, SAT Scores, and Pell Grant seem to non-linearly correlated with the response variable. Thus we use appropriate smooth splines to adjust for an additive model, with smooth splines fit on non-linear predictors with an effective degree of freedom of 4: 

Additive Model 2: $\log(Median Earning) \sim \beta_0 + r1(s(Price, 4)) + r2(s(SAT, 4)) + r3(s(Pell Grant, 4)) + \beta_4(Student Loan) + \epsilon$   

We control for a covariate by adding it into our model, like SAT scores and prior economic status, to separate the effects it has on the main predictor of interest Price. This can help us account for these covariates' effects on the response variable and better study the actual effects Price has on Median Earnings. **(2)**

   
```{r}
# models= data.frame(Linear=fitted(model1), Additive=fitted(model2))
# plot(Additive ~ Linear, data = models, xlab = "Linear Model 1", ylab = "Additive Model 2", pch=".")
```

Figure 3 shows the residual analysis of the linear model and Figure 4 for the additive model. The residual plots of tow models show that both residuals are not fully randomly distributed since the residuals tend to scatter at the center, though there are no obvious patterns for the distributions. The residuals are approximately centered around the zero-line and almost have constant variance across observations despite some outliers are observed at the two ends. The normal QQ plots show that residuals are mostly falling along the best-fit line but still some outliers at both ends. Histograms show that both residuals are unimodal and bit right skewed which make them not perfectly normal. Thus I believe the two models roughly preserve most of the linearity and normality assumptions but some tweaks on the variables can still be applied. Some transformation on the predictors can be implemented or taking the effect of interaction terms between variables into account in further research. **(3)**

```{r, fig.width=5, fig.height=3, fig.cap="Residual analysis of the linear model"}
par(mfrow = c(1, 3))
plot(fitted(model1), residuals(model1), pch=".", xlab="Fitted values", ylab="Residuals", main="Model 1 Residuals")
abline(h=0, lty=5)

qqnorm(resid(model1), main="Normal QQ plot Model1") 
qqline(resid(model1))

hist(residuals(model1), main="Histogram of Model 1 Residuals", xlab="Residuals")
```

```{r, fig.width=5, fig.height=3, fig.cap="Residual analysis of the additive model"}
par(mfrow = c(1, 3))
plot(fitted(model2), residuals(model2), pch=".", xlab="Fitted values", ylab="Residuals", main="Model 2 Residuals")
abline(h=0, lty=5)

qqnorm(resid(model2), main="Normal QQ plot Model2") 
qqline(resid(model2))

hist(residuals(model2), main="Histogram of Model 2 Residuals", xlab="Residuals")
```


```{r, results='hide'}
set.seed(2020)

n <- nrow(college)
folds <- sample(rep(1:5, length=n), replace=FALSE) 
cv <- matrix(NA, 2, 5)
rownames(cv) <- c("Model 1", "Model 2")
for (k in 1:5) {
   train <- college[folds != k,]
   test <- college[folds == k,]
   # Model 1
   cv[1, k] <- mean((test$MD_EARN_WNE_P10 - exp(predict(model1, newdata=test)))^2)
   # Model 2
   cv[2, k] <- mean((test$MD_EARN_WNE_P10 - exp(predict(model2, newdata=test)))^2) 
}

MSE = apply(cv, 1, mean)
SE = apply(cv, 1, sd)/sqrt(5)
MSE
SE
```

We use 5-fold cross-validation to determine which one the two model makes a better fit to the college dataset. The following table shows the estimated MSE and standard error from cross-validation: 

Table 1: Prediction Error from 5-fold Cross-Validation

|                | Linear Model | Additive Model |
|----------------|--------------|----------------|
| Estimated MSE  | 53301187     | 50785912       |
| Standard Error | 3507752      | 3343988        |


The results indicate that the Additive Model 2 has a lower MSE and a smaller SE, which outperformed the linear model in both fields. **(4)** This can be explained by the characteristic of additive model since it allows lower bias than parametric bootstrapping results and add more flexibility.

   
```{r, eval=FALSE}
y1 = fitted(model1)
y2 = fitted(model2)
sum((college$MD_EARN_WNE_P10 - y1) ^ 2)
sum((college$MD_EARN_WNE_P10 - y2) ^ 2)
```

```{r, eval=FALSE}
anova(model1, model2, test = "F")
```

There seems to be no significant difference between two models although we believe Model 2 is better fit to the data. The training error of both models are around $2.477*10^{12}$ but the estimated MSE and SE of the additive model are lower that those of the linear model. The adjusted R-squared for the linear model is 50.9% while that of the additive model is higher at 53.1%. We perform an ANOVA F-test on the tow models and get a p-value of $7.945*10^{-9}$. Since the p-value is much lower than 0.05, we have sufficient evidence to reject the null hypothesis (linear model) and in favor of the additive model. **(5)** Based on the residual analysis of the additive model, residuals seem to have some correlation with observations since some assumptions might be violated. Since we do not know the exact distribution of residuals, we will proceed with bootstrapping by resampling residuals for this data. **(6)**


# Results


We find that for schools with very low tuition or very high ones, there is a negative relationship between Price and Median Earnings as indicated by Figure 5. For schools the majority of schools with tuition between 10000 and 30000, there is a positive relationship. Thus we can see that the majority of the schools demonstrate a positive relationship between Price and Earnings.

```{r, fig.width=5, fig.height=4, fig.cap = "Smooth Spline for Price"}
plot(model2, se = TRUE, select =1)
```


Using the additive model we choose, Figure 6 displays the relationship between school tuition and predicted future earnings, holding other variables constant. The dots are the predict values and the lowess line shows the regression trend line. We can clearly see that as Price increases, the amount of earnings also increase on average, holding other variables constant. The expected Median Earnings increase at a relatively slow rate if Price is less than 20000, since it only increases about 5000 if Price goes from 10000 to 20000. But the slope increases at a faster speed for Price larger than 20000, reaching an roughly added amount of 8000 if Price goes from 30000 to 40000. **(1)** All the p-values of the predictors included in the additive model are less than 0.05, indicating that they are all statistically significant and the model is valid. The model accounts for 53.1% of variability in the response variable, which is a fair amount for this dataset. 
   
```{r, fig.width=5, fig.height=4, fig.cap="Do students who attend more expensive schools earn more after graduation"}
y = predict(model2, newdata = college)
plot(college$PRICE, exp(y), xlab = "Price", ylab = "Median Earnings", pch = ".", main = "Prediction of Median Earnings vs. Price on Additive Model")
lines(lowess(exp(y) ~ college$PRICE, f=8/10, iter=3), lty=1, col="blue")
```
   

```{r}
null = gam(log(MD_EARN_WNE_P10) ~ s(PRICE, k = 4 + 1, fx = TRUE) + CONTROL + s(SAT_AVG_ALL, k = 4 + 1, fx = TRUE) + s(PCTPELL, 
        k = 4 + 1, fx = TRUE) + PCTFLOAN , data = college)
alt = gam(log(MD_EARN_WNE_P10) ~ s(PRICE, k = 4 + 1, by = CONTROL, fx = TRUE) + CONTROL + s(SAT_AVG_ALL, k = 4 + 1, fx = TRUE) +                s(PCTPELL, k = 4 + 1, fx = TRUE) + PCTFLOAN , data = college)
```

```{r}
anova(null, alt, test = "F")
```   
 
It is interesting to find out whether the relationship between price and earnings is the same at public, private, and for-profit solutions. We include an interaction term in our model and use ANOVA F-test again on a reduced model and a full model to see if controlling for different institution types will cause a difference in the prediction. The hypotheses are the following:
  
$H_0: \text{The relationship between price and earnings is the same at public, private, and for-profit solutions.}$
$H_A: \text{The relationship between price and earnings is different at public, private, and for-profit solutions.}$
  
The ANOVA F-test yields a p-value of 0.01897, which is less than 0.05. Thus have sufficient evidence to reject the null at a 95% confidence level, and conclude that the relationship between price and earnings is different at public, private, and for-profit solutions. This result is based on the assumption that the residuals are independent and normally distributed, and homoscedasticity is preserved. **(2)**
   
   
```{r, warning=FALSE}

CMU_pred = predict(model2, newdata = college[which(college$INSTNM == "Carnegie Mellon University"), ], se.fit = TRUE, interval = "confidence")

exp(CMU_pred$fit + CMU_pred$se.fit * qnorm(0.975) * c(-1, 1))

exp(predict(model2, newdata = college[which(college$INSTNM == "Carnegie Mellon University"), ], se.fit = TRUE, interval = "confidence")$fit)
```

As a Carnegie Mellon student, I would like to use my model to estimate for the mean earnings of students after graduation for a school just like Carnegie Mellon. The lower limit of the confidence interval is 65870.69, upper limit 71994.53, and the fit is 68864.57. Thus we are 95% confident that the mean earnings of students after graduation for a school just like Carnegie Mellon is between [65870.69, 71994.53]. The assumptions are the chosen model is similar to the true model, and residuals are normally distributed.**(3)** 
   

```{r}
set.seed(2020)
B = 1000
cmu = college[which(college$INSTNM == "Carnegie Mellon University"), ]
confint = matrix(NA, nrow = B, ncol = 2)

q1 = qt(0.025, nrow(college)-5)
q2 = qt(0.975, nrow(college)-5)
for (b in 1:B) {
  noise <- residuals(model2)[sample(nrow(college), replace=T)]
  rhat.new = exp(fitted(model2) + noise)
  #out <- lm(log(rhat.new) ~ SAT_AVG_ALL + PCTPELL + PCTFLOAN + PRICE, data = college)
  out = gam(log(rhat.new) ~ s(PRICE, k = 4 + 1, fx = TRUE) + s(SAT_AVG_ALL, k = 4 + 1, fx = TRUE) + s(PCTPELL, k = 4 + 1,                        fx = TRUE) + PCTFLOAN , data = college)
  pred = predict(out, newdata = cmu, se.fit = TRUE)
  yhat.new = pred$fit
  sehat.new = pred$se.fit
  confint[b, 1] = exp(yhat.new - q2*sehat.new)
  confint[b, 2] = exp(yhat.new - q1*sehat.new)
}
apply(confint, 2, mean)
```

The 95% confidence interval computed from pivotal bootstrapping by resampling residuals is [65930.45, 72037.08]. This interval is similiar to the previous one with the two bounds shift up a bit. This method is based on the assumption that the model’s residuals are independent of each other with constant variance. We believe that the bootstrapping conﬁdence interval is more reliable since it does not make any assumptions on the actual distribution of residuals, while the confidence interval computed from our model assumed that residuals are normal but might not be true. **(4)**



